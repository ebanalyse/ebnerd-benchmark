{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "In this notebook, we illustrate how to use the Neural News Recommendation with Multi-Head Self-Attention ([NRMS](https://aclanthology.org/D19-1671/)). The implementation is taken from the [recommenders](https://github.com/recommenders-team/recommenders) repository. We have simply stripped the model to keep it cleaner.\n",
    "\n",
    "We use a small dataset, which is downloaded from [recsys.eb.dk](https://recsys.eb.dk/). All the datasets are stored in the folder path ```~/ebnerd_data/*```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes.kruse/coding/ebnerd-benchmark/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "import datetime\n",
    "\n",
    "from ebrec.utils._constants import *\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    "    ebnerd_from_path,\n",
    ")\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Available devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"~/ebnerd_data\").expanduser()\n",
    "#\n",
    "DATASPLIT = \"ebnerd_small\"\n",
    "DUMP_DIR = Path(\"ebnerd_predictions\")\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History size can often be a memory bottleneck; if adjusted, the NRMS hyperparameter ```history_size``` must be updated to ensure compatibility and efficient memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_SIZE = 20\n",
    "hparams_nrms.history_size = HISTORY_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just want to load the necessary columns\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "# This notebook is just a simple 'get-started'; we down sample the number of samples to just run quickly through it.\n",
    "FRACTION = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we sample the dataset, just to keep it smaller. We'll split the training data into training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2007\n",
      "Validation samples: 335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>labels</th></tr><tr><td>u32</td><td>u32</td><td>datetime[μs]</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>list[i8]</td></tr></thead><tbody><tr><td>161621</td><td>183774532</td><td>2023-05-22 11:14:26</td><td>[9769765, 9768583, … 9768002]</td><td>[9771197]</td><td>[9775716, 9775699, … 9771113]</td><td>[0, 0, … 0]</td></tr><tr><td>861733</td><td>390446134</td><td>2023-05-20 14:30:49</td><td>[9770989, 9769553, … 9769575]</td><td>[9772866]</td><td>[9773543, 9746810, … 9773543]</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ impression_i ┆ impression_t ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      │\n",
       "│ ---     ┆ d            ┆ ime          ┆ ixed         ┆ clicked      ┆ inview       ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ u32          ┆ datetime[μs] ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 161621  ┆ 183774532    ┆ 2023-05-22   ┆ [9769765,    ┆ [9771197]    ┆ [9775716,    ┆ [0, 0, … 0] │\n",
       "│         ┆              ┆ 11:14:26     ┆ 9768583, …   ┆              ┆ 9775699, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9768002]     ┆              ┆ 9771113]     ┆             │\n",
       "│ 861733  ┆ 390446134    ┆ 2023-05-20   ┆ [9770989,    ┆ [9772866]    ┆ [9773543,    ┆ [0, 0, … 0] │\n",
       "│         ┆              ┆ 14:30:49     ┆ 9769553, …   ┆              ┆ 9746810, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9769575]     ┆              ┆ 9773543]     ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(DATASPLIT, \"train\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "dt_split = pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).max() - datetime.timedelta(days=1)\n",
    "df_train = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) < dt_split)\n",
    "df_validation = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) >= dt_split)\n",
    "\n",
    "print(f\"Train samples: {df_train.height}\\nValidation samples: {df_validation.height}\")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set\n",
    "We'll use the validation set, as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(DATASPLIT, \"validation\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3000022</td><td>&quot;Hanks beskyldt…</td><td>&quot;Tom Hanks har …</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Tom Hanks skul…</td><td>2006-09-20 09:24:18</td><td>[3518381]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;David Gardner&quot;]</td><td>[&quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Litteratur&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9911</td><td>&quot;Negative&quot;</td></tr><tr><td>3000063</td><td>&quot;Bostrups aske …</td><td>&quot;Studieværten b…</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Strålende sens…</td><td>2006-09-24 07:45:30</td><td>[3170935, 3170939]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, … &quot;Personlig begivenhed&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.5155</td><td>&quot;Neutral&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3000022   ┆ Hanks     ┆ Tom Hanks ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9911    ┆ Negative │\n",
       "│           ┆ beskyldt  ┆ har angiv ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ for misha ┆ eligt     ┆ 06:20:32  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ndling    ┆ mishand…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000063   ┆ Bostrups  ┆ Studievær ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.5155    ┆ Neutral  │\n",
       "│           ┆ aske      ┆ ten blev  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ spredt i  ┆ mindet    ┆ 06:20:32  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Furesøen  ┆ med gla…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes.kruse/coding/ebnerd-benchmark/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs.\n",
    "\n",
    "Note, with this ```NRMSDataLoader``` the ```eval_mode=False``` is meant for ```model.model.fit()``` whereas ```eval_mode=True``` is meant for ```model.scorer.predict()```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Available devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the NRMS-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "model.model.compile(\n",
    "    optimizer=model.model.optimizer,\n",
    "    loss=model.model.loss,\n",
    "    metrics=[\"AUC\"],\n",
    ")\n",
    "\n",
    "MODEL_NAME = model.__class__.__name__\n",
    "MODEL_WEIGHTS = DUMP_DIR.joinpath(f\"state_dict/{MODEL_NAME}/weights\")\n",
    "LOG_DIR = DUMP_DIR.joinpath(f\"runs/{MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "We will add some callbacks to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard:\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=LOG_DIR,\n",
    "    histogram_freq=1,\n",
    ")\n",
    "\n",
    "# Earlystopping:\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# ModelCheckpoint:\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS,\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Learning rate scheduler:\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "callbacks = [tensorboard_callback, early_stopping, modelcheckpoint, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 3.4206 - auc: 0.4980\n",
      "Epoch 1: val_auc improved from -inf to 0.50956, saving model to ebnerd_predictions/state_dict/NRMSModel/weights\n",
      "63/63 [==============================] - 257s 4s/step - loss: 3.4206 - auc: 0.4980 - val_loss: 2.2938 - val_auc: 0.5096 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "USE_CALLBACKS = True\n",
    "EPOCHS = 1\n",
    "\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks if USE_CALLBACKS else [],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CALLBACKS:\n",
    "    _ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TEST = 16\n",
    "\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 142s 923ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.scorer.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the predictions to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>labels</th><th>scores</th></tr><tr><td>u32</td><td>u32</td><td>datetime[μs]</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>list[i8]</td><td>list[f64]</td></tr></thead><tbody><tr><td>1823980</td><td>30777836</td><td>2023-05-26 11:08:08</td><td>[9778769, 9777182, … 9779996]</td><td>[9782421]</td><td>[9782180, 9782421, … 9782391]</td><td>[0, 1, … 0]</td><td>[0.996318, 0.99995, … 0.999989]</td></tr><tr><td>799160</td><td>41754374</td><td>2023-05-25 12:17:22</td><td>[9779674, 9779511, … 9779860]</td><td>[9780514]</td><td>[9780856, 9780514, … 9780791]</td><td>[0, 1, … 0]</td><td>[0.999377, 0.999693, … 0.999579]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 8)\n",
       "┌─────────┬────────────┬────────────┬────────────┬────────────┬────────────┬───────────┬───────────┐\n",
       "│ user_id ┆ impression ┆ impression ┆ article_id ┆ article_id ┆ article_id ┆ labels    ┆ scores    │\n",
       "│ ---     ┆ _id        ┆ _time      ┆ _fixed     ┆ s_clicked  ┆ s_inview   ┆ ---       ┆ ---       │\n",
       "│ u32     ┆ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---        ┆ list[i8]  ┆ list[f64] │\n",
       "│         ┆ u32        ┆ datetime[μ ┆ list[i32]  ┆ list[i32]  ┆ list[i32]  ┆           ┆           │\n",
       "│         ┆            ┆ s]         ┆            ┆            ┆            ┆           ┆           │\n",
       "╞═════════╪════════════╪════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ 1823980 ┆ 30777836   ┆ 2023-05-26 ┆ [9778769,  ┆ [9782421]  ┆ [9782180,  ┆ [0, 1, …  ┆ [0.996318 │\n",
       "│         ┆            ┆ 11:08:08   ┆ 9777182, … ┆            ┆ 9782421, … ┆ 0]        ┆ ,         │\n",
       "│         ┆            ┆            ┆ 9779996]   ┆            ┆ 9782391]   ┆           ┆ 0.99995,  │\n",
       "│         ┆            ┆            ┆            ┆            ┆            ┆           ┆ …         │\n",
       "│         ┆            ┆            ┆            ┆            ┆            ┆           ┆ 0.999989] │\n",
       "│ 799160  ┆ 41754374   ┆ 2023-05-25 ┆ [9779674,  ┆ [9780514]  ┆ [9780856,  ┆ [0, 1, …  ┆ [0.999377 │\n",
       "│         ┆            ┆ 12:17:22   ┆ 9779511, … ┆            ┆ 9780514, … ┆ 0]        ┆ ,         │\n",
       "│         ┆            ┆            ┆ 9779860]   ┆            ┆ 9780791]   ┆           ┆ 0.999693, │\n",
       "│         ┆            ┆            ┆            ┆            ┆            ┆           ┆ …         │\n",
       "│         ┆            ┆            ┆            ┆            ┆            ┆           ┆ 0.999579] │\n",
       "└─────────┴────────────┴────────────┴────────────┴────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = add_prediction_scores(df_test, pred_test.tolist())\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC:   0%|                                             | 0/2446 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "AUC: 100%|████████████████████████████████| 2446/2446 [00:00<00:00, 2672.11it/s]\n",
      "AUC: 100%|██████████████████████████████| 2446/2446 [00:00<00:00, 102841.55it/s]\n",
      "AUC: 100%|███████████████████████████████| 2446/2446 [00:00<00:00, 42990.74it/s]\n",
      "AUC: 100%|███████████████████████████████| 2446/2446 [00:00<00:00, 43055.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.5019162034296264,\n",
       "    \"mrr\": 0.31422072947587976,\n",
       "    \"ndcg@5\": 0.3451454383469061,\n",
       "    \"ndcg@10\": 0.42719144948301424\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_test[\"labels\"].to_list(),\n",
    "    predictions=df_test[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>labels</th><th>scores</th><th>ranked_scores</th></tr><tr><td>u32</td><td>u32</td><td>datetime[μs]</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>list[i8]</td><td>list[f64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>1823980</td><td>30777836</td><td>2023-05-26 11:08:08</td><td>[9778769, 9777182, … 9779996]</td><td>[9782421]</td><td>[9782180, 9782421, … 9782391]</td><td>[0, 1, … 0]</td><td>[0.996318, 0.99995, … 0.999989]</td><td>[6, 3, … 1]</td></tr><tr><td>799160</td><td>41754374</td><td>2023-05-25 12:17:22</td><td>[9779674, 9779511, … 9779860]</td><td>[9780514]</td><td>[9780856, 9780514, … 9780791]</td><td>[0, 1, … 0]</td><td>[0.999377, 0.999693, … 0.999579]</td><td>[5, 2, … 3]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id ┆ impression ┆ impressio ┆ article_i ┆ … ┆ article_i ┆ labels    ┆ scores    ┆ ranked_sc │\n",
       "│ ---     ┆ _id        ┆ n_time    ┆ d_fixed   ┆   ┆ ds_inview ┆ ---       ┆ ---       ┆ ores      │\n",
       "│ u32     ┆ ---        ┆ ---       ┆ ---       ┆   ┆ ---       ┆ list[i8]  ┆ list[f64] ┆ ---       │\n",
       "│         ┆ u32        ┆ datetime[ ┆ list[i32] ┆   ┆ list[i32] ┆           ┆           ┆ list[i64] │\n",
       "│         ┆            ┆ μs]       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1823980 ┆ 30777836   ┆ 2023-05-2 ┆ [9778769, ┆ … ┆ [9782180, ┆ [0, 1, …  ┆ [0.996318 ┆ [6, 3, …  │\n",
       "│         ┆            ┆ 6         ┆ 9777182,  ┆   ┆ 9782421,  ┆ 0]        ┆ ,         ┆ 1]        │\n",
       "│         ┆            ┆ 11:08:08  ┆ …         ┆   ┆ …         ┆           ┆ 0.99995,  ┆           │\n",
       "│         ┆            ┆           ┆ 9779996]  ┆   ┆ 9782391]  ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.999989] ┆           │\n",
       "│ 799160  ┆ 41754374   ┆ 2023-05-2 ┆ [9779674, ┆ … ┆ [9780856, ┆ [0, 1, …  ┆ [0.999377 ┆ [5, 2, …  │\n",
       "│         ┆            ┆ 5         ┆ 9779511,  ┆   ┆ 9780514,  ┆ 0]        ┆ ,         ┆ 3]        │\n",
       "│         ┆            ┆ 12:17:22  ┆ …         ┆   ┆ …         ┆           ┆ 0.999693, ┆           │\n",
       "│         ┆            ┆           ┆ 9779860]  ┆   ┆ 9780791]  ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.999579] ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.with_columns(\n",
    "    pl.col(\"scores\")\n",
    "    .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "    .alias(\"ranked_scores\")\n",
    ")\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: CodaBench is only evaluating ebnerd_testset (1.5GB); hence, this is just a dummy version using the validation set. You need to use the test set in your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2446it [00:00, 27609.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping ebnerd_predictions/predictions.txt to ebnerd_predictions/ebnerd_small_predictions-NRMSModel.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_submission_file(\n",
    "    impression_ids=df_test[DEFAULT_IMPRESSION_ID_COL],\n",
    "    prediction_scores=df_test[\"ranked_scores\"],\n",
    "    path=DUMP_DIR.joinpath(\"predictions.txt\"),\n",
    "    filename_zip=f\"{DATASPLIT}_predictions-{MODEL_NAME}.zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
